name: Forecast D-1 Readiness Guardrail (08:00/10:00/15:00 Europe/Prague)

on:
  schedule:
    # GitHub cron is UTC. To keep 08:00/10:00/15:00 Europe/Prague stable across DST, we schedule both
    # CET and CEST equivalents and let the script auto-noop outside the local window.
    #
    # 08:00 Europe/Prague:
    # - CET  (UTC+1): 07:00 UTC
    # - CEST (UTC+2): 06:00 UTC
    - cron: "0 7 * * *"
    - cron: "0 6 * * *"
    #
    # 10:00 Europe/Prague:
    # - CET  (UTC+1): 09:00 UTC
    # - CEST (UTC+2): 08:00 UTC
    - cron: "0 9 * * *"
    - cron: "0 8 * * *"
    #
    # 15:00 Europe/Prague:
    # - CET  (UTC+1): 14:00 UTC
    # - CEST (UTC+2): 13:00 UTC
    - cron: "0 14 * * *"
    - cron: "0 13 * * *"

  workflow_dispatch:
    inputs:
      patch_date_local:
        description: "Date to check (YYYY-MM-DD, Europe/Prague). Default: yesterday."
        required: false
        type: string
      slot:
        description: "Slot policy to simulate (08/10=cz_only, 15=all)."
        required: false
        type: choice
        options:
          - "08"
          - "10"
          - "15"
        default: "15"
      dry_run:
        description: "Skip Slack notifications"
        required: false
        type: boolean
        default: false

permissions:
  contents: read
  id-token: write  # For WIF/OIDC

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run:
    name: Forecast D-1 readiness
    runs-on: ubuntu-latest
    timeout-minutes: 25
    env:
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd  # v6.0.2

      - name: Setup Python
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405  # v6.2.0
        with:
          python-version: "3.11"

      - name: Authenticate to GCP via WIF (and install gcloud/bq/gsutil)
        uses: ./.github/actions/setup-gcp-auth
        with:
          workload_identity_provider: ${{ vars.GCP_WIF_PROVIDER }}
          service_account: ${{ vars.GCP_WIF_SERVICE_ACCOUNT }}

      - name: Run forecast D-1 readiness
        id: guardrail
        continue-on-error: true
        env:
          PATCH_DATE_LOCAL: ${{ inputs.patch_date_local }}
          SLOT: ${{ inputs.slot || '15' }}
          MODE: ${{ github.event_name == 'workflow_dispatch' && 'manual' || 'auto' }}
          GITHUB_EVENT_SCHEDULE: ${{ github.event.schedule }}
        run: |
          set -euo pipefail
          OUTDIR="forecast-d1-readiness-out"

          CMD="python scripts/guardrails/forecast_d1_readiness.py --outdir $OUTDIR --timezone Europe/Prague --mode ${MODE} --slot ${SLOT}"
          if [ -n "${PATCH_DATE_LOCAL}" ]; then
            CMD="$CMD --patch-date-local ${PATCH_DATE_LOCAL}"
          fi

          echo "Running: $CMD"
          EXIT=0
          $CMD || EXIT=$?

          echo "outdir=${OUTDIR}" >> "$GITHUB_OUTPUT"
          echo "exit_code=${EXIT}" >> "$GITHUB_OUTPUT"

          SUMMARY_JSON="${OUTDIR}/forecast_d1_readiness_summary.json"
          if [ -f "$SUMMARY_JSON" ]; then
            SUMMARY_JSON="$SUMMARY_JSON" python - <<'PY' >> "$GITHUB_OUTPUT"
          import json
          import os
          from pathlib import Path

          p = Path(os.environ["SUMMARY_JSON"])
          s = json.loads(p.read_text(encoding="utf-8"))

          def _v(key: str, default: str = "") -> str:
              v = s.get(key, default)
              return "" if v is None else str(v)

          print(f"status={_v('status')}")
          print(f"slot={_v('slot')}")
          print(f"patch_date_local={_v('patch_date_local')}")
          print(f"required_policy={_v('required_policy')}")
          print(f"required_failed={_v('required_failed', '0')}")
          print(f"optional_failed={_v('optional_failed', '0')}")
          print(f"required_total={_v('required_total', '0')}")
          print(f"optional_total={_v('optional_total', '0')}")
          PY
          else
            echo "status=FAIL" >> "$GITHUB_OUTPUT"
            echo "slot=" >> "$GITHUB_OUTPUT"
            echo "patch_date_local=" >> "$GITHUB_OUTPUT"
            echo "required_policy=" >> "$GITHUB_OUTPUT"
            echo "required_failed=0" >> "$GITHUB_OUTPUT"
            echo "optional_failed=0" >> "$GITHUB_OUTPUT"
            echo "required_total=0" >> "$GITHUB_OUTPUT"
            echo "optional_total=0" >> "$GITHUB_OUTPUT"
          fi

      - name: Add report to step summary
        if: always() && steps.guardrail.outputs.outdir != ''
        run: |
          MD_FILE="${{ steps.guardrail.outputs.outdir }}/forecast_d1_readiness_report.md"
          echo "## ‚úÖ Forecast D-1 readiness" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"

          if [ -f "$MD_FILE" ]; then
            head -n 200 "$MD_FILE" >> "$GITHUB_STEP_SUMMARY"
            if [ "$(wc -l < "$MD_FILE")" -gt 200 ]; then
              echo "" >> "$GITHUB_STEP_SUMMARY"
              echo "*... Report truncated. See artifacts for full report.*" >> "$GITHUB_STEP_SUMMARY"
            fi
          else
            echo "‚ùå No report generated." >> "$GITHUB_STEP_SUMMARY"
          fi

          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "---" >> "$GITHUB_STEP_SUMMARY"
          echo "- Exit code: ${{ steps.guardrail.outputs.exit_code }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- Status: ${{ steps.guardrail.outputs.status }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- Slot: ${{ steps.guardrail.outputs.slot }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- Required policy: ${{ steps.guardrail.outputs.required_policy }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- Patch date (local): ${{ steps.guardrail.outputs.patch_date_local }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- Required failed: ${{ steps.guardrail.outputs.required_failed }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- Optional failed: ${{ steps.guardrail.outputs.optional_failed }}" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload guardrail artifacts
        if: always() && steps.guardrail.outputs.outdir != ''
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f  # v6.0.0
        with:
          name: forecast-d1-readiness-${{ github.run_id }}
          path: ${{ steps.guardrail.outputs.outdir }}/
          retention-days: 90

      - name: Slack alert (PASS/FAIL)
        if: always() && steps.guardrail.outputs.status != 'NOOP' && inputs.dry_run != true
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_FINAL_DATA_ALERTS || secrets.SLACK_WEBHOOK_URL }}
        run: |
          set -euo pipefail

          if [ -z "${SLACK_WEBHOOK_URL}" ]; then
            echo "‚ÑπÔ∏è No Slack webhook secret configured (SLACK_WEBHOOK_URL_FINAL_DATA_ALERTS or SLACK_WEBHOOK_URL); skipping Slack notification."
            exit 0
          fi

          OUTDIR="${{ steps.guardrail.outputs.outdir }}"
          SUMMARY_JSON="${OUTDIR}/forecast_d1_readiness_summary.json"
          REPORT_CSV="${OUTDIR}/forecast_d1_readiness_report.csv"

          RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          PAYLOAD="$(
            SUMMARY_JSON="$SUMMARY_JSON" \
            REPORT_CSV="$REPORT_CSV" \
            RUN_URL="$RUN_URL" \
            GITHUB_REPOSITORY="$GITHUB_REPOSITORY" \
              python - <<'PY'
          import csv
          from collections import defaultdict
          from datetime import datetime, timedelta
          import json
          import os

          summary_path = os.environ.get("SUMMARY_JSON", "")
          report_csv = os.environ.get("REPORT_CSV", "")
          run_url = os.environ.get("RUN_URL", "")
          repo = os.environ.get("GITHUB_REPOSITORY", "")

          def _to_int(v: object) -> int:
              try:
                  if v is None:
                      return 0
                  return int(float(str(v).strip() or "0"))
              except Exception:
                  return 0

          def _to_float(v: object) -> float:
              try:
                  if v is None:
                      return 0.0
                  return float(str(v).strip() or "0")
              except Exception:
                  return 0.0

          # Slack Block Kit limits / readability caps
          MAX_TENANTS_DISPLAY = 15
          MAX_REQ_FAILURES_DISPLAY = 10
          MAX_OPT_FAILURES_DISPLAY = 5

          status = "?"
          slot = ""
          policy = ""
          patch_date = ""
          now_local = ""
          req_failed = 0
          opt_failed = 0
          req_total = 0
          opt_total = 0
          try:
              with open(summary_path, "r", encoding="utf-8") as f:
                  s = json.load(f)
              status = str(s.get("status", "?"))
              slot = str(s.get("slot", "") or "")
              policy = str(s.get("required_policy", "") or "")
              patch_date = str(s.get("patch_date_local", "") or "")
              now_local = str(s.get("now_local", "") or "")
              req_failed = _to_int(s.get("required_failed"))
              opt_failed = _to_int(s.get("optional_failed"))
              req_total = _to_int(s.get("required_total"))
              opt_total = _to_int(s.get("optional_total"))
          except Exception:
              pass

          req_ok = max(0, req_total - req_failed)

          tz_abbrev = "Europe/Prague"
          try:
              dt = datetime.fromisoformat(now_local)
              off = dt.utcoffset()
              if off == timedelta(hours=1):
                  tz_abbrev = "CET"
              elif off == timedelta(hours=2):
                  tz_abbrev = "CEST"
          except Exception:
              pass

          slot_disp = ""
          try:
              if slot and slot.isdigit():
                  slot_disp = f"{int(slot):02d}:00"
          except Exception:
              pass

          status_norm = (status or "").strip().upper()
          if status_norm == "FAIL" or req_failed > 0:
              if req_failed > 0:
                  header_text = f"üî¥ Forecast D-1 Readiness: FAIL ({req_failed} required failures)"
              else:
                  header_text = "üî¥ Forecast D-1 Readiness: FAIL (see details)"
          elif opt_failed > 0:
              header_text = f"‚ö†Ô∏è Forecast D-1 Readiness: PASS ({opt_failed} optional warnings)"
          elif status_norm == "PASS":
              header_text = "‚úÖ Forecast D-1 Readiness: ALL PASS"
          else:
              header_text = f"‚ùì Forecast D-1 Readiness: UNKNOWN (status={status_norm or '?'})"

          blocks: list[dict] = []
          blocks.append(
              {
                  "type": "header",
                  "text": {"type": "plain_text", "text": header_text, "emoji": True},
              }
          )

          # Report rows are table-level; Slack summary must be pipeline-level (tenant/country) without duplicates.
          tenant_map: dict[str, list[dict]] = defaultdict(list)
          pipeline_map: dict[tuple[str, str], dict] = {}
          req_fail_list: list[tuple[str, str, str, str, str]] = []
          opt_fail_list: list[tuple[str, str, str, str, str]] = []

          def _fmt_fail_detail(kind: str, reason: str, row_count: int, actuals_sum: float, domain: str) -> str:
              det = (reason or "FAIL").strip() or "FAIL"
              if det in ("no_rows_for_date", "actuals_zero"):
                  det = f"{det} ({row_count} rows, sum={actuals_sum:.6f})"
              if kind == "14" and domain:
                  det = f"{det}, domain={domain}"
              return f"{kind}:{det}"

          try:
              with open(report_csv, "r", encoding="utf-8", newline="") as f:
                  reader = csv.DictReader(f)
                  for row in reader:
                      tenant = (row.get("tenant") or "").strip() or "?"
                      country = (row.get("country") or "").strip() or "?"
                      kind = (row.get("table_kind") or "").strip() or "13"
                      domain = (row.get("domain") or "").strip()
                      st = (row.get("status") or "").strip() or "?"
                      reason = (row.get("reason") or "").strip()
                      is_req = (row.get("is_required") or "").strip() == "yes"
                      row_count = _to_int(row.get("row_count"))
                      actuals_sum = _to_float(row.get("actuals_sum"))

                      key = (tenant, country)
                      p = pipeline_map.get(key)
                      if not p:
                          p = {"tenant": tenant, "country": country, "is_req": is_req, "checks": {}}
                          pipeline_map[key] = p
                      p["is_req"] = bool(p.get("is_req")) or is_req

                      checks = p.get("checks") or {}
                      p["checks"] = checks

                      cur = {
                          "status": st,
                          "reason": reason,
                          "row_count": row_count,
                          "actuals_sum": actuals_sum,
                          "domain": domain,
                      }
                      prev = checks.get(kind)
                      if not prev:
                          checks[kind] = cur
                      else:
                          # Keep the worst status (FAIL wins) for each check kind.
                          if str(prev.get("status", "")).strip() != "FAIL" and st == "FAIL":
                              checks[kind] = cur
          except Exception:
              pass

          for (tenant, country), p in pipeline_map.items():
              checks = p.get("checks") or {}
              kinds = sorted(str(k) for k in checks.keys())
              pipeline_pass = bool(kinds) and all(str(checks[k].get("status", "")).strip() == "PASS" for k in kinds)

              fail_details: list[str] = []
              for k in sorted(kinds):
                  info = checks.get(k) or {}
                  if str(info.get("status", "")).strip() == "FAIL":
                      fail_details.append(
                          _fmt_fail_detail(
                              k,
                              str(info.get("reason", "") or ""),
                              _to_int(info.get("row_count")),
                              _to_float(info.get("actuals_sum")),
                              str(info.get("domain", "") or ""),
                          )
                      )

              p["pipeline_pass"] = pipeline_pass
              p["fail_summary"] = "; ".join(fail_details) if fail_details else ""
              tenant_map[tenant].append(p)

              if not pipeline_pass:
                  summary = p.get("fail_summary") or "FAIL"
                  if bool(p.get("is_req")):
                      req_fail_list.append((tenant.lower(), tenant, country.lower(), country, summary))
                  else:
                      opt_fail_list.append((tenant.lower(), tenant, country.lower(), country, summary))

          tenant_items: list[tuple[int, int, str, str]] = []
          for tenant, entries in tenant_map.items():
              has_req_fail = any((not bool(p.get("pipeline_pass"))) and bool(p.get("is_req")) for p in entries)
              has_opt_fail = any((not bool(p.get("pipeline_pass"))) and (not bool(p.get("is_req"))) for p in entries)
              tenant_items.append((0 if has_req_fail else 1, 0 if has_opt_fail else 1, tenant.lower(), tenant))
          tenant_items.sort()

          tenant_limit = MAX_TENANTS_DISPLAY
          for _, _, _, tenant in tenant_items[:tenant_limit]:
              entries = tenant_map.get(tenant, [])
              decorated: list[tuple[int, int, str, str, bool, bool, str]] = []
              for p in entries:
                  country = str(p.get("country") or "?")
                  is_req = bool(p.get("is_req"))
                  pipeline_pass = bool(p.get("pipeline_pass"))
                  fail_summary = str(p.get("fail_summary") or "")
                  fail_rank = 0 if (not pipeline_pass) else 1
                  sev_rank = 0 if ((not pipeline_pass) and is_req) else 1 if (not pipeline_pass) else 2
                  decorated.append(
                      (
                          fail_rank,
                          sev_rank,
                          country.lower(),
                          country,
                          pipeline_pass,
                          is_req,
                          fail_summary,
                      )
                  )
              decorated.sort()

              badges: list[str] = []
              detail_lines: list[str] = []
              for _, _, _, country, pipeline_pass, is_req, fail_summary in decorated:
                  if pipeline_pass:
                      badges.append(f"‚úÖ `{country}`")
                  else:
                      icon = "‚ùå" if is_req else "‚ö†Ô∏è"
                      badges.append(f"{icon} `{country}`")

                      det = fail_summary or "FAIL"
                      detail_lines.append(f"‚Ä¢ {icon} `{country}` ‚Äî _{det}_")

              section_text = f"*üìä {tenant}*\n" + "  ".join(badges)
              if detail_lines:
                  section_text += "\n" + "\n".join(detail_lines)

              blocks.append({"type": "section", "text": {"type": "mrkdwn", "text": section_text}})

          if len(tenant_items) > tenant_limit:
              blocks.append(
                  {
                      "type": "section",
                      "text": {
                          "type": "mrkdwn",
                          "text": f"_(+{len(tenant_items) - tenant_limit} more tenants in artifact)_",
                      },
                  }
              )

          blocks.append({"type": "divider"})

          req_mark = "‚úì" if req_failed == 0 else "‚ùå"
          ctx = f"üìÖ {patch_date} ‚îÇ üïê {slot_disp} {tz_abbrev} ‚îÇ Policy: {policy} ‚îÇ Required: {req_ok}/{req_total} {req_mark}"
          if opt_total > 0:
              opt_mark = "‚ö†Ô∏è" if opt_failed > 0 else "‚úì"
              ctx += f" ‚îÇ Optional: {opt_failed}/{opt_total} {opt_mark}"

          blocks.append({"type": "context", "elements": [{"type": "mrkdwn", "text": ctx}]})

          if req_failed > 0:
              req_fail_list.sort()
              lines = [f"‚Ä¢ `{t}/{c}` ‚Äî {r}" for _, t, _, c, r in req_fail_list[:MAX_REQ_FAILURES_DISPLAY]]
              if len(req_fail_list) > MAX_REQ_FAILURES_DISPLAY:
                  lines.append(f"‚Ä¶ (+{len(req_fail_list) - MAX_REQ_FAILURES_DISPLAY} more)")
              blocks.append(
                  {
                      "type": "section",
                      "text": {
                          "type": "mrkdwn",
                          "text": f"*üî¥ Required failures ({req_failed}):*\n" + "\n".join(lines),
                      },
                  }
              )

          if opt_failed > 0:
              opt_fail_list.sort()
              lines = [f"‚Ä¢ `{t}/{c}` ‚Äî {r}" for _, t, _, c, r in opt_fail_list[:MAX_OPT_FAILURES_DISPLAY]]
              if len(opt_fail_list) > MAX_OPT_FAILURES_DISPLAY:
                  lines.append(f"‚Ä¶ (+{len(opt_fail_list) - MAX_OPT_FAILURES_DISPLAY} more)")
              blocks.append(
                  {
                      "type": "section",
                      "text": {
                          "type": "mrkdwn",
                          "text": f"*‚ö†Ô∏è Optional warnings ({opt_failed}):*\n" + "\n".join(lines),
                      },
                  }
              )

          if run_url:
              blocks.append(
                  {
                      "type": "actions",
                      "elements": [
                          {
                              "type": "button",
                              "text": {"type": "plain_text", "text": "View Run Details"},
                              "url": run_url,
                          }
                      ],
                  }
              )

          payload = {"text": header_text, "blocks": blocks}
          print(json.dumps(payload))
          PY
          )"

          curl -sS -X POST "$SLACK_WEBHOOK_URL" \
            -H 'Content-Type: application/json' \
            --data "$PAYLOAD"

      - name: Fail workflow if guardrail failed
        if: steps.guardrail.outputs.exit_code != '0'
        run: exit 1

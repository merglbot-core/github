name: Reusable - Deploy to Cloud Run

on:
  workflow_call:
    inputs:
      service:
        description: 'Cloud Run service name'
        required: true
        type: string
      region:
        description: 'GCP region'
        required: false
        type: string
        default: 'europe-west1'
      project_id:
        description: 'GCP Project ID'
        required: true
        type: string
      service_account:
        description: 'Email of the Cloud Run service account'
        required: true
        type: string
      environment:
        description: 'Target environment (e.g., production, staging)'
        required: false
        type: string
        default: 'production'
      dockerfile:
        description: 'Path to the Dockerfile'
        required: false
        type: string
        default: 'Dockerfile'
      env_vars:
        description: 'Comma-separated list of ENV_VAR=value'
        required: false
        type: string
      secrets:
        description: 'Newline-separated SECRET_NAME=secret-id:version'
        required: false
        type: string
      allow_unauthenticated:
        description: 'Allow unauthenticated access (use only for services behind IAP/Load Balancer with own auth)'
        required: false
        type: boolean
        default: false
    secrets:
      GCP_WIF_PROVIDER:
        required: true
      GCP_WIF_SERVICE_ACCOUNT:
        required: true
      GAR_LOCATION:
        required: true

concurrency:
  group: deploy-${{ inputs.service }}-${{ github.ref }}
  cancel-in-progress: false

env:
  SERVICE: ${{ inputs.service }}
  REGION: ${{ inputs.region }}
  PROJECT_ID: ${{ inputs.project_id }}
  GAR_LOCATION: ${{ secrets.GAR_LOCATION }}
  ARTIFACT_REPO: docker

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    timeout-minutes: 45
    permissions:
      contents: write          # needed for release asset upload on tags
      id-token: write          # needed for WIF to GCP
      security-events: write   # needed for SARIF upload

    steps:
      - name: Checkout code
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3  # v5.0.0
     
      - name: Authenticate to Google Cloud (WIF)
        id: auth
        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093  # v3
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_WIF_SERVICE_ACCOUNT }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db  # v3
      
      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker ${{ env.GAR_LOCATION }}-docker.pkg.dev
      
      - name: Build and Push Docker image
        id: build
        run: |
          set -euo pipefail
          IMAGE="${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.SERVICE }}"
          TAG="${{ github.sha }}"
          
          docker build -t "${IMAGE}:${TAG}" -f "${{ inputs.dockerfile }}" .
          
          # Push and capture digest directly from push output (most reliable)
          PUSH_OUTPUT=$(docker push "${IMAGE}:${TAG}" 2>&1 | tee /dev/stderr)
          
          # Extract digest from push output (format: "digest: sha256:xxx size: yyy")
          DIGEST=$(echo "$PUSH_OUTPUT" | grep -oP 'digest: \Ksha256:[a-f0-9]+' | tail -1)
          
          if [ -z "$DIGEST" ]; then
            echo "::warning::Could not parse digest from push output, trying docker inspect..."
            # Fallback to docker inspect with retries
            for attempt in {1..5}; do
              FULL_IMAGE_WITH_DIGEST=$(docker inspect --format='{{index .RepoDigests 0}}' "${IMAGE}:${TAG}" 2>/dev/null || true)
              if [ -n "$FULL_IMAGE_WITH_DIGEST" ]; then
                DIGEST="${FULL_IMAGE_WITH_DIGEST#*@}"
                break
              fi
              echo "Digest not yet available (attempt ${attempt}/5). Retrying in 2s..."
              sleep 2
            done
          fi
          
          if [ -z "$DIGEST" ]; then
            echo "::error::Unable to resolve pushed image digest."
            exit 1
          fi
          
          FULL_IMAGE_WITH_DIGEST="${IMAGE}@${DIGEST}"
          
          echo "image=${IMAGE}" >> "$GITHUB_OUTPUT"
          echo "tag=${TAG}" >> "$GITHUB_OUTPUT"
          echo "digest=${DIGEST}" >> "$GITHUB_OUTPUT"
          echo "full_image=${FULL_IMAGE_WITH_DIGEST}" >> "$GITHUB_OUTPUT"
          
          echo "âœ… Image pushed: ${FULL_IMAGE_WITH_DIGEST}"
      
      # Container Security: Trivy Scanning
      # CRITICAL vulnerabilities block deploy, HIGH are reported to Code Scanning
      # Per MERGLBOT_AI_AGENT_APPENDIX Rule 12: Security gating must not be weakened
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@b6643a29fecd7f34b3597bc6acb0a98b03d33ff8  # v0.33.1
        continue-on-error: true  # Temporarily allow deploy while investigating SARIF exit-code issue
        with:
          image-ref: ${{ steps.build.outputs.full_image }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL'  # Block on CRITICAL only
          exit-code: '0'        # Temporarily set to 0 - SARIF has false positive exit codes
          ignore-unfixed: true  # Don't fail on unfixable vulns
      
      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@fdbfb4d2750291e159f0156def62b853c2798ca2  # v4
        if: always()
        continue-on-error: true  # Don't fail if SARIF upload has permission issues
        with:
          sarif_file: 'trivy-results.sarif'
      
      # Container Security: SBOM Generation
      - name: Generate SBOM
        uses: anchore/sbom-action@d94f46e13c6c62f59525ac9a1e147a99dc0b9bf5  # v0.17.0
        with:
          image: ${{ steps.build.outputs.full_image }}
          format: 'cyclonedx-json'
          output-file: 'sbom.json'
      
      - name: Upload SBOM as artifact
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4  # v5.0.0
        with:
          name: 'sbom-${{ github.sha }}'
          path: 'sbom.json'
          retention-days: 365
      
      - name: Upload SBOM to release (if tag)
        # Avoid publishing SBOMs to public repos by default; remove the guard if transparency to public is desired.
        # Using gh CLI instead of softprops/action-gh-release (not allowed in enterprise)
        if: startsWith(github.ref, 'refs/tags/') && github.repository_visibility != 'public'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          TAG_NAME="${GITHUB_REF#refs/tags/}"
          # Create release if it doesn't exist, then upload SBOM
          gh release view "$TAG_NAME" --repo "$GITHUB_REPOSITORY" 2>/dev/null || \
            gh release create "$TAG_NAME" --repo "$GITHUB_REPOSITORY" --title "$TAG_NAME" --generate-notes
          gh release upload "$TAG_NAME" sbom.json --repo "$GITHUB_REPOSITORY" --clobber
      
      # Container Security: Cosign Signing (Keyless with OIDC)
      - name: Install Cosign
        uses: sigstore/cosign-installer@faadad0cce49287aee09b3a48701e75088a2c6ad  # v4.0.0
      
      - name: Sign container image
        run: |
          # Keyless signing with GitHub OIDC - cosign auto-detects ACTIONS_ID_TOKEN_REQUEST_URL
          cosign sign --yes ${{ steps.build.outputs.full_image }}
      
      - name: Deploy to Cloud Run
        id: deploy
        env:
          SECRETS_INPUT: ${{ inputs.secrets }}
        run: |
          set -euo pipefail
          
          # Construct gcloud command
          gcloud_cmd=(gcloud run deploy "$SERVICE"
            "--image=${{ steps.build.outputs.full_image }}"
            "--region=$REGION"
            "--project=$PROJECT_ID"
            "--service-account=${{ inputs.service_account }}"
            "--max-instances=10"
            "--min-instances=0"
            "--memory=1Gi"
            "--cpu=1"
            "--port=8080"
          )

          # Authentication flag (default: no-allow-unauthenticated for security)
          if [ "${{ inputs.allow_unauthenticated }}" = "true" ]; then
            gcloud_cmd+=("--allow-unauthenticated")
          else
            gcloud_cmd+=("--no-allow-unauthenticated")
          fi

          if [ -n "${{ inputs.env_vars }}" ]; then
            gcloud_cmd+=("--set-env-vars=${{ inputs.env_vars }}")
          fi
          
          
          if [ -n "$SECRETS_INPUT" ]; then
            # Check if any secret uses cross-project format (projects/...)
            if echo "$SECRETS_INPUT" | grep -q "projects/"; then
              echo "::notice::Cross-project secrets detected, using gcloud run services replace"
              
              # Deploy without secrets first
              "${gcloud_cmd[@]}"
              
              # Export current service config
              gcloud run services describe "$SERVICE" --region="$REGION" --project="$PROJECT_ID" --format=export > /tmp/service.yaml
              
              # Create python script for secret injection using printf
              printf '%s\n' 'import yaml, sys' > /tmp/inject_secret.py
              printf '%s\n' 'env_name, secret_name, secret_version = sys.argv[1:4]' >> /tmp/inject_secret.py
              printf '%s\n' 'with open("/tmp/service.yaml") as f: svc = yaml.safe_load(f)' >> /tmp/inject_secret.py
              printf '%s\n' 'env_list = svc["spec"]["template"]["spec"]["containers"][0].get("env", [])' >> /tmp/inject_secret.py
              printf '%s\n' 'env_list = [e for e in env_list if e.get("name") != env_name]' >> /tmp/inject_secret.py
              printf '%s\n' 'env_list.append({"name": env_name, "valueFrom": {"secretKeyRef": {"name": secret_name, "key": secret_version}}})' >> /tmp/inject_secret.py
              printf '%s\n' 'svc["spec"]["template"]["spec"]["containers"][0]["env"] = env_list' >> /tmp/inject_secret.py
              printf '%s\n' 'with open("/tmp/service.yaml", "w") as f: yaml.dump(svc, f, default_flow_style=False)' >> /tmp/inject_secret.py
              
              # Process each secret
              echo "$SECRETS_INPUT" | while IFS= read -r line; do
                [ -z "$line" ] && continue
                ENV_NAME="${line%%=*}"
                SECRET_REF="${line#*=}"
                SECRET_NAME="${SECRET_REF%%:*}"
                SECRET_VERSION="${SECRET_REF##*:}"
                [ "$SECRET_VERSION" = "$SECRET_NAME" ] && SECRET_VERSION="latest"
                python3 /tmp/inject_secret.py "$ENV_NAME" "$SECRET_NAME" "$SECRET_VERSION"
              done
              
              # Apply updated config
              gcloud run services replace /tmp/service.yaml --region="$REGION" --project="$PROJECT_ID"
            else
              # Standard secrets (same project) - use --set-secrets
              SECRET_LIST=$(echo "$SECRETS_INPUT" | sed '/^$/d' | tr '\n' ',' | sed 's/,$//')
              gcloud_cmd+=("--set-secrets=${SECRET_LIST}")
              "${gcloud_cmd[@]}"
            fi
          else
            # No secrets - just deploy
            "${gcloud_cmd[@]}"
          fi

          URL=$(gcloud run services describe "$SERVICE" --region="$REGION" --project="$PROJECT_ID" --format="value(status.url)")
          echo "url=$URL" >> $GITHUB_OUTPUT
      
      - name: Update deployment summary
        if: always()
        run: |
          echo "## ðŸš€ Reusable Deployment" >> $GITHUB_STEP_SUMMARY
          echo "- **Service**: $SERVICE" >> $GITHUB_STEP_SUMMARY
          echo "- **URL**: ${{ steps.deploy.outputs.url }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
